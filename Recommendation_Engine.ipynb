{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "COLOR, TEXTURE AND SHAPE SIMILARITY"
      ],
      "metadata": {
        "id": "urh4uXhY5SBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless numpy scikit-image"
      ],
      "metadata": {
        "id": "X4gADVGgNtus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries and define utility functions\n",
        "\n",
        "!pip install opencv-python-headless numpy scikit-image\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor\n",
        "from scipy.spatial.distance import euclidean\n",
        "from google.colab import files\n",
        "import os\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def upload_images():\n",
        "    uploaded = files.upload()\n",
        "    return list(uploaded.keys())\n",
        "\n",
        "def read_image(file_path):\n",
        "    return cv2.imread(file_path)\n",
        "\n",
        "# Define similarity functions\n",
        "\n",
        "def calculate_color_similarity(image1, image2):\n",
        "    def calculate_color_histogram(image):\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
        "        cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
        "        return hist.flatten()\n",
        "\n",
        "    hist1 = calculate_color_histogram(image1)\n",
        "    hist2 = calculate_color_histogram(image2)\n",
        "    bhattacharyya_dist = cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)\n",
        "\n",
        "    return bhattacharyya_dist\n",
        "\n",
        "def calculate_shape_similarity(image1, image2):\n",
        "    def hu_moments(image):\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        moments = cv2.moments(gray)\n",
        "        hu_moments = cv2.HuMoments(moments).flatten()\n",
        "        return -np.sign(hu_moments) * np.log10(np.abs(hu_moments))\n",
        "\n",
        "    hu1 = hu_moments(image1)\n",
        "    hu2 = hu_moments(image2)\n",
        "    hu_dist = euclidean(hu1, hu2)\n",
        "\n",
        "    return hu_dist\n",
        "\n",
        "def calculate_texture_similarities(image1, image2):\n",
        "    # LBP comparison using KL divergence\n",
        "    def lbp_histogram(image, num_points=24, radius=8, eps=1e-7):\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        lbp = local_binary_pattern(gray, num_points, radius, method=\"uniform\")\n",
        "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
        "        hist = hist.astype(\"float\")\n",
        "        hist /= (hist.sum() + eps)\n",
        "        return hist\n",
        "\n",
        "    def kl_divergence(p, q):\n",
        "        return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
        "\n",
        "    lbp1 = lbp_histogram(image1)\n",
        "    lbp2 = lbp_histogram(image2)\n",
        "    lbp_dist = kl_divergence(lbp1, lbp2)\n",
        "\n",
        "    # Gabor feature comparison\n",
        "    def gabor_features(image):\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        features = []\n",
        "        for theta in range(4):\n",
        "            theta = theta / 4. * np.pi\n",
        "            for sigma in (1, 3):\n",
        "                for frequency in (0.05, 0.25):\n",
        "                    filt_real, filt_imag = gabor(gray, frequency=frequency, theta=theta, sigma_x=sigma, sigma_y=sigma)\n",
        "                    features.append(filt_real.mean())\n",
        "                    features.append(filt_imag.mean())\n",
        "        return np.array(features)\n",
        "\n",
        "    gabor1 = gabor_features(image1)\n",
        "    gabor2 = gabor_features(image2)\n",
        "    gabor_dist = euclidean(gabor1, gabor2)\n",
        "\n",
        "    return lbp_dist, gabor_dist\n",
        "\n",
        "# Main function to compare images\n",
        "\n",
        "def compare_images():\n",
        "    print(\"Please upload the images you want to compare:\")\n",
        "    image_files = upload_images()\n",
        "\n",
        "    if len(image_files) != 2:\n",
        "        print(\"Please upload exactly two images.\")\n",
        "        return\n",
        "\n",
        "    image1 = read_image(image_files[0])\n",
        "    image2 = read_image(image_files[1])\n",
        "\n",
        "    if image1 is None or image2 is None:\n",
        "        print(\"Error reading one or both images.\")\n",
        "        return\n",
        "\n",
        "    color_dist = calculate_color_similarity(image1, image2)\n",
        "    shape_dist = calculate_shape_similarity(image1, image2)\n",
        "    lbp_dist, gabor_dist = calculate_texture_similarities(image1, image2)\n",
        "\n",
        "    print(f\"Comparing {image_files[0]} and {image_files[1]}:\")\n",
        "    print(f\"Color Similarity (Bhattacharyya Distance): {color_dist:.4f}\")\n",
        "    print(f\"Shape Similarity (Hu Moment, Euclidean Distance): {shape_dist:.4f}\")\n",
        "    print(f\"Texture Similarity (LBP, KL Divergence): {lbp_dist:.4f}\")\n",
        "    print(f\"Texture Similarity (Gabor, Euclidean Distance): {gabor_dist:.4f}\")\n",
        "\n",
        "# Run this function to compare images\n",
        "compare_images()\n",
        "\n",
        "!pip install opencv-python-headless numpy scikit-image annoy\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor\n",
        "from scipy.spatial.distance import euclidean\n",
        "from google.colab import files\n",
        "from annoy import AnnoyIndex\n",
        "import random\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor\n",
        "from annoy import AnnoyIndex\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the earrings folder\n",
        "base_path = '/content/drive/MyDrive/earrings/'\n",
        "\n",
        "def read_image(file_path):\n",
        "    return cv2.imread(file_path)\n",
        "\n",
        "def calculate_color_histogram(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
        "    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
        "    return hist.flatten()\n",
        "\n",
        "def calculate_hu_moments(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    moments = cv2.moments(gray)\n",
        "    hu_moments = cv2.HuMoments(moments).flatten()\n",
        "    return -np.sign(hu_moments) * np.log10(np.abs(hu_moments))\n",
        "\n",
        "def calculate_lbp_histogram(image, num_points=24, radius=8, eps=1e-7):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    lbp = local_binary_pattern(gray, num_points, radius, method=\"uniform\")\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + eps)\n",
        "    return hist\n",
        "\n",
        "def calculate_gabor_features(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    features = []\n",
        "    for theta in range(4):\n",
        "        theta = theta / 4. * np.pi\n",
        "        for sigma in (1, 3):\n",
        "            for frequency in (0.05, 0.25):\n",
        "                filt_real, filt_imag = gabor(gray, frequency=frequency, theta=theta, sigma_x=sigma, sigma_y=sigma)\n",
        "                features.append(filt_real.mean())\n",
        "                features.append(filt_imag.mean())\n",
        "    return np.array(features)\n",
        "\n",
        "def extract_features(image):\n",
        "    color_hist = calculate_color_histogram(image)\n",
        "    hu_moments = calculate_hu_moments(image)\n",
        "    lbp_hist = calculate_lbp_histogram(image)\n",
        "    gabor_features = calculate_gabor_features(image)\n",
        "    return np.concatenate([color_hist, hu_moments, lbp_hist, gabor_features])\n",
        "\n",
        "def build_annoy_index(features, n_trees=10, index_file='image_similarity_index.ann'):\n",
        "    feature_length = features.shape[1]\n",
        "    index = AnnoyIndex(feature_length, 'angular')\n",
        "    for i, feature in enumerate(features):\n",
        "        index.add_item(i, feature)\n",
        "    index.build(n_trees)\n",
        "    index.save(index_file)\n",
        "    return index\n",
        "\n",
        "def find_similar_images(index, features, query_index, n=5):\n",
        "    similar_indices = index.get_nns_by_vector(features[query_index], n+1)[1:]  # exclude self\n",
        "    return [(i, index.get_distance(query_index, i)) for i in similar_indices]\n",
        "\n",
        "def process_images_with_annoy():\n",
        "    image_files = [f for f in os.listdir(base_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    features = []\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(base_path, img_file)\n",
        "        image = read_image(img_path)\n",
        "        if image is not None:\n",
        "            feature = extract_features(image)\n",
        "            features.append(feature)\n",
        "        else:\n",
        "            print(f\"Failed to read image: {img_file}\")\n",
        "\n",
        "    features = np.array(features)\n",
        "\n",
        "    # Build Annoy index\n",
        "    index = build_annoy_index(features)\n",
        "\n",
        "    # Example: Find similar images for the first image\n",
        "    query_index = 0\n",
        "    similar_images = find_similar_images(index, features, query_index)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Images similar to {image_files[query_index]}:\")\n",
        "    for idx, distance in similar_images:\n",
        "        print(f\"Similar image: {image_files[idx]}, Distance: {distance}\")\n",
        "\n",
        "# Run the process\n",
        "process_images_with_annoy()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X8YhYI4AEz8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ANNOY INDEX"
      ],
      "metadata": {
        "id": "tgqKqK7rwicF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless numpy scikit-image annoy\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor\n",
        "from scipy.spatial.distance import euclidean\n",
        "from google.colab import files\n",
        "from annoy import AnnoyIndex\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJlVapSq0YLF",
        "outputId": "4d8c3821-d7e1-45b0-c1e1-76982610a7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/647.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/647.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp310-cp310-linux_x86_64.whl size=550734 sha256=cb3466d17f0387ad24eb8b2063a809b76aeaa62596cc21ff2ac02829366ec435\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/8a/da/f714bcf46c5efdcfcac0559e63370c21abe961c48e3992465a\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor\n",
        "from annoy import AnnoyIndex\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the earrings folder\n",
        "base_path = '/content/drive/MyDrive/earrings/'\n",
        "\n",
        "def read_image(file_path):\n",
        "    return cv2.imread(file_path)\n",
        "\n",
        "def calculate_color_histogram(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
        "    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
        "    return hist.flatten()\n",
        "\n",
        "def calculate_hu_moments(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    moments = cv2.moments(gray)\n",
        "    hu_moments = cv2.HuMoments(moments).flatten()\n",
        "    return -np.sign(hu_moments) * np.log10(np.abs(hu_moments))\n",
        "\n",
        "def calculate_lbp_histogram(image, num_points=24, radius=8, eps=1e-7):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    lbp = local_binary_pattern(gray, num_points, radius, method=\"uniform\")\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + eps)\n",
        "    return hist\n",
        "\n",
        "def calculate_gabor_features(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    features = []\n",
        "    for theta in range(4):\n",
        "        theta = theta / 4. * np.pi\n",
        "        for sigma in (1, 3):\n",
        "            for frequency in (0.05, 0.25):\n",
        "                filt_real, filt_imag = gabor(gray, frequency=frequency, theta=theta, sigma_x=sigma, sigma_y=sigma)\n",
        "                features.append(filt_real.mean())\n",
        "                features.append(filt_imag.mean())\n",
        "    return np.array(features)\n",
        "\n",
        "def extract_features(image):\n",
        "    color_hist = calculate_color_histogram(image)\n",
        "    hu_moments = calculate_hu_moments(image)\n",
        "    lbp_hist = calculate_lbp_histogram(image)\n",
        "    gabor_features = calculate_gabor_features(image)\n",
        "    return np.concatenate([color_hist, hu_moments, lbp_hist, gabor_features])\n",
        "\n",
        "def build_annoy_index(features, n_trees=10, index_file='image_similarity_index.ann'):\n",
        "    feature_length = features.shape[1]\n",
        "    index = AnnoyIndex(feature_length, 'angular')\n",
        "    for i, feature in enumerate(features):\n",
        "        index.add_item(i, feature)\n",
        "    index.build(n_trees)\n",
        "    index.save(index_file)\n",
        "    return index\n",
        "\n",
        "def find_similar_images(index, features, query_index, n=5):\n",
        "    similar_indices = index.get_nns_by_vector(features[query_index], n+1)[1:]  # exclude self\n",
        "    return [(i, index.get_distance(query_index, i)) for i in similar_indices]\n",
        "\n",
        "def process_images_with_annoy():\n",
        "    image_files = [f for f in os.listdir(base_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    features = []\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(base_path, img_file)\n",
        "        image = read_image(img_path)\n",
        "        if image is not None:\n",
        "            feature = extract_features(image)\n",
        "            features.append(feature)\n",
        "        else:\n",
        "            print(f\"Failed to read image: {img_file}\")\n",
        "\n",
        "    features = np.array(features)\n",
        "\n",
        "    # Build Annoy index\n",
        "    index = build_annoy_index(features)\n",
        "\n",
        "    # Example: Find similar images for the first image\n",
        "    query_index = 0\n",
        "    similar_images = find_similar_images(index, features, query_index)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Images similar to {image_files[query_index]}:\")\n",
        "    for idx, distance in similar_images:\n",
        "        print(f\"Similar image: {image_files[idx]}, Distance: {distance}\")\n",
        "\n",
        "# Run the process\n",
        "process_images_with_annoy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuumgD2KuW1b",
        "outputId": "057074cd-b9ef-4738-99bf-74ff22fc3d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Images similar to 502415SAEAGA09_1 (2).jpg:\n",
            "Similar image: 502415SAEAGA09_1 (1).jpg, Distance: 0.0\n",
            "Similar image: 502415SAEAGA09_1.jpg, Distance: 0.0\n",
            "Similar image: 511183DQJABA18_1.jpg, Distance: 0.007114844862371683\n",
            "Similar image: 500487SAAABA15_1.jpg, Distance: 0.008710759691894054\n",
            "Similar image: 511417DDPABA00_1.jpg, Distance: 0.009248176589608192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ball Tree"
      ],
      "metadata": {
        "id": "nLQqKdKt5H48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wdyYtZN5A65",
        "outputId": "0da83052-dd1d-44e2-bd8a-65dba4e861a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor\n",
        "from sklearn.neighbors import BallTree\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the earrings folder in your drive\n",
        "base_path = '/content/drive/MyDrive/earrings/'\n",
        "\n",
        "def read_image(file_path):\n",
        "    return cv2.imread(file_path)\n",
        "\n",
        "def calculate_color_histogram(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
        "    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
        "    return hist.flatten()\n",
        "\n",
        "def calculate_hu_moments(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    moments = cv2.moments(gray)\n",
        "    hu_moments = cv2.HuMoments(moments).flatten()\n",
        "    return -np.sign(hu_moments) * np.log10(np.abs(hu_moments))\n",
        "\n",
        "def calculate_lbp_histogram(image, num_points=24, radius=8, eps=1e-7):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    lbp = local_binary_pattern(gray, num_points, radius, method=\"uniform\")\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + eps)\n",
        "    return hist\n",
        "\n",
        "def calculate_gabor_features(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    features = []\n",
        "    for theta in range(4):\n",
        "        theta = theta / 4. * np.pi\n",
        "        for sigma in (1, 3):\n",
        "            for frequency in (0.05, 0.25):\n",
        "                filt_real, filt_imag = gabor(gray, frequency=frequency, theta=theta, sigma_x=sigma, sigma_y=sigma)\n",
        "                features.append(filt_real.mean())\n",
        "                features.append(filt_imag.mean())\n",
        "    return np.array(features)\n",
        "\n",
        "def extract_features(image):\n",
        "    color_hist = calculate_color_histogram(image)\n",
        "    hu_moments = calculate_hu_moments(image)\n",
        "    lbp_hist = calculate_lbp_histogram(image)\n",
        "    gabor_features = calculate_gabor_features(image)\n",
        "    return np.concatenate([color_hist, hu_moments, lbp_hist, gabor_features])\n",
        "\n",
        "def build_balltree(features):\n",
        "    return BallTree(features)\n",
        "\n",
        "def find_similar_images(tree, features, query_index, n=5):\n",
        "    distances, indices = tree.query(features[query_index:query_index+1], k=n+1)\n",
        "    return list(zip(indices[0][1:], distances[0][1:]))  # exclude self\n",
        "\n",
        "def process_images_with_balltree():\n",
        "    print(f\"Searching for images in: {base_path}\")\n",
        "    image_files = [f for f in os.listdir(base_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No image files found in {base_path}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(image_files)} images.\")\n",
        "\n",
        "    features = []\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(base_path, img_file)\n",
        "        image = read_image(img_path)\n",
        "        if image is not None:\n",
        "            feature = extract_features(image)\n",
        "            features.append(feature)\n",
        "        else:\n",
        "            print(f\"Failed to read image: {img_file}\")\n",
        "\n",
        "    features = np.array(features)\n",
        "\n",
        "    # Build BallTree\n",
        "    tree = build_balltree(features)\n",
        "\n",
        "    # Example: Find similar images for the first image\n",
        "    query_index = 0\n",
        "    similar_images = find_similar_images(tree, features, query_index)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Images similar to {image_files[query_index]}:\")\n",
        "    for idx, distance in similar_images:\n",
        "        print(f\"Similar image: {image_files[idx]}, Distance: {distance}\")\n",
        "\n",
        "# Run the process\n",
        "process_images_with_balltree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TAxTWqpx8vE",
        "outputId": "5aa17ef8-d61a-42c9-ce1a-6e60ef6b3455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Searching for images in: /content/drive/MyDrive/earrings/\n",
            "Found 396 images.\n",
            "Images similar to 502415SAEAGA09_1 (2).jpg:\n",
            "Similar image: 502415SAEAGA09_1 (1).jpg, Distance: 0.0\n",
            "Similar image: 502415SAEAGA09_1 (2).jpg, Distance: 0.0\n",
            "Similar image: 502014SFDAGA52_1.jpg, Distance: 5.866915218908919\n",
            "Similar image: 501055SHCABB09_1.jpg, Distance: 6.255253685312517\n",
            "Similar image: 511417DDPABA00_1.jpg, Distance: 6.377874593903574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barlow Twins Embeddings"
      ],
      "metadata": {
        "id": "ybXjJ8DoQOxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "train_tfms = T.Compose([\n",
        "    T.Resize(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(*imagenet_stats,inplace=True),\n",
        "])\n",
        "\n",
        "valid_tfms = T.Compose([\n",
        "    T.Resize(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(*imagenet_stats)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "XTbZGvwPQRzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the earrings folder in your drive\n",
        "data_dir = '/content/drive/MyDrive/earrings/'\n",
        "\n",
        "dataset = ImageFolder(data_dir, transform=train_tfms)\n",
        "\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed);\n",
        "\n",
        "val_size = int(0.2 * len(dataset))\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "# Split into train and validation dataset\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "batch_size=4\n",
        "\n",
        "# Training and validation dataloaders\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=1, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size, num_workers=1, pin_memory=True)"
      ],
      "metadata": {
        "id": "kFtqEmGGQe10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub_(m).div_(s)\n",
        "        return tensor\n",
        "\n",
        "def shown_example(img, label):\n",
        "    '''display an image with class name and label'''\n",
        "    print('Label:', train_ds.dataset.classes[label], '('+str(label)+')')\n",
        "    #check for the number of channels\n",
        "    if (img.size()[0] == 3):\n",
        "        unorm_image = unorm(img)\n",
        "        plt.imshow(unorm_image.permute(1,2,0))\n",
        "    else:\n",
        "        unorm_image = unorm(img)\n",
        "        plt.imshow(unorm_image.squeeze())\n",
        "\n",
        "def show_batch(dl):\n",
        "    '''display a batch of images'''\n",
        "    for images, labels in dl:\n",
        "        norm_images = images.clone()\n",
        "        unorm_images = []\n",
        "        for img in images:\n",
        "            unorm_image = unorm(img)\n",
        "            unorm_images.append(unorm_image)\n",
        "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(24,18))\n",
        "        axs[0].set_xticks([])\n",
        "        axs[0].set_yticks([])\n",
        "        axs[1].set_xticks([])\n",
        "        axs[1].set_yticks([])\n",
        "        axs[0].imshow(make_grid(norm_images, nrow=8).permute(1,2,0))\n",
        "        axs[1].imshow(make_grid(unorm_images, nrow=8).permute(1,2,0))\n",
        "        break\n",
        "\n",
        "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"
      ],
      "metadata": {
        "id": "GaNLv8g0QoVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shown_example(*train_ds[0])"
      ],
      "metadata": {
        "id": "0TSyFAFNQpve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
        "model.cuda();"
      ],
      "metadata": {
        "id": "-jKrVe4-Qrb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from torchvision.io.image import read_image\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
        "from torchcam.cams import ScoreCAM, SSCAM, ISCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "\n",
        "def plot_cam(img_path, cam_extractor, model):\n",
        "    # Get your input\n",
        "    img = read_image(img_path)\n",
        "\n",
        "    # Preprocess it for your chosen model\n",
        "    input_tensor = normalize(resize(img, (224, 224)) / 255., [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "    # Preprocess your data and feed it to the model\n",
        "    out = model(input_tensor.unsqueeze(0).cuda())\n",
        "    # Retrieve the CAM by passing the class index and the model output\n",
        "    activation_map = cam_extractor(out.squeeze(0).argmax().item(), out)\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(8,4))\n",
        "\n",
        "    # Visualize the raw CAM\n",
        "    axs[0].imshow(activation_map.cpu().numpy());plt.axis('off'); axs[0].set_xticks([]); axs[0].set_yticks([])\n",
        "\n",
        "    # Resize the CAM and overlay it\n",
        "    result = overlay_mask(to_pil_image(img), to_pil_image(activation_map, mode='F'), alpha=0.5)\n",
        "    # Display it\n",
        "    axs[1].imshow(result); plt.axis('off'); plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "40a2aBBPQu87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cam_extractor = ScoreCAM(model)"
      ],
      "metadata": {
        "id": "2EHd7a3OQwhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict_dl(dl, model):\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_preds = []\n",
        "    for xb, _ in tqdm(dl):\n",
        "        # Get predictions from model\n",
        "        yb = model(xb.cuda())\n",
        "        # Pick index with highest probability\n",
        "        _, preds  = torch.max(yb, dim=1)\n",
        "        batch_preds.append(preds)\n",
        "    batch_preds = torch.cat(batch_preds)\n",
        "    return batch_preds"
      ],
      "metadata": {
        "id": "95uH8Q9sQx4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveFeatures():\n",
        "    features=None\n",
        "    def __init__(self, m):\n",
        "        self.hook = m.register_forward_hook(self.hook_fn)\n",
        "        self.features = None\n",
        "    def hook_fn(self, module, input, output):\n",
        "        output = output.squeeze(3)\n",
        "        output = output.squeeze(2)\n",
        "        out = output.detach().cpu().numpy()\n",
        "        if isinstance(self.features, type(None)):\n",
        "            self.features = out\n",
        "        else:\n",
        "            self.features = np.row_stack((self.features, out))\n",
        "    def remove(self):\n",
        "        self.hook.remove()"
      ],
      "metadata": {
        "id": "p3QN9YP_QzuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf = SaveFeatures(model.avgpool)"
      ],
      "metadata": {
        "id": "xIg5yMd6Q0Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(dataset, batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "predictions = predict_dl(dl, model)"
      ],
      "metadata": {
        "id": "bL9IVUl-Q1vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "id": "z9amAnP7Q3RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = [x[0] for x in (list(dl.dataset.imgs))]\n",
        "label = [dl.dataset.classes[x[1]] for x in (list(dl.dataset.imgs))]\n",
        "label_id = [x[1] for x in (list(dl.dataset.imgs))]"
      ],
      "metadata": {
        "id": "QLYVf-ECQ4jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(img_path), len(label), len(label_id)"
      ],
      "metadata": {
        "id": "fMnXKTNbQ5yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.DataFrame({'img_path': img_path, 'label': label, 'label_id': label_id})\n",
        "df_new.head()"
      ],
      "metadata": {
        "id": "N0XQy6OrQ7h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new['label'].value_counts()"
      ],
      "metadata": {
        "id": "Qld1N4HvQ885"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = sf.features\n",
        "x=array.tolist()\n",
        "df_new['img_repr'] = x"
      ],
      "metadata": {
        "id": "QNZHjqSpQ-Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x[0])"
      ],
      "metadata": {
        "id": "TbQFXpg8Q_xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.to_csv('barlow_twins_earrings_embeddings.csv')"
      ],
      "metadata": {
        "id": "J7SSE7lURBbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fZrOO0A4RDTP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}